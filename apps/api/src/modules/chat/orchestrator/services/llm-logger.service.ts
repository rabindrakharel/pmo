/**
 * Centralized LLM Logger Service
 * Consolidates ALL agent context, conversations, LLM calls, and responses into llm.log
 * @module orchestrator/services/llm-logger
 */

import fs from 'fs/promises';
import path from 'path';
import type { AgentContextState } from '../agents/agent-context.service.js';
import type { ChatCompletionMessageParam } from 'openai/resources/chat/completions';

/**
 * LLM Logger Service
 * Single source of truth for all LLM-related logging
 */
export class LLMLoggerService {
  private logFilePath: string;
  private logDir: string = './logs';

  constructor() {
    this.logFilePath = path.join(this.logDir, 'llm.log');
    this.initializeLogFile();
  }

  /**
   * Initialize log file and directory
   */
  private async initializeLogFile(): Promise<void> {
    try {
      await fs.mkdir(this.logDir, { recursive: true });

      // Create initial log file with header if it doesn't exist
      try {
        await fs.access(this.logFilePath);
      } catch {
        const header = `
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        COMPREHENSIVE LLM ACTIVITY LOG                          â•‘
â•‘                                                                                â•‘
â•‘  This file contains ALL LLM calls, agent context, conversations, and          â•‘
â•‘  decisions made by the multi-agent orchestration system.                      â•‘
â•‘                                                                                â•‘
â•‘  Log Started: ${new Date().toISOString()}                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

`;
        await fs.writeFile(this.logFilePath, header, 'utf-8');
      }

      console.log(`[LLMLogger] ğŸ“ Logging all LLM activity to: ${this.logFilePath}`);
    } catch (error: any) {
      console.error(`[LLMLogger] âŒ Failed to initialize log file: ${error.message}`);
    }
  }

  /**
   * Append to log file
   */
  private async appendToLog(content: string): Promise<void> {
    try {
      await fs.appendFile(this.logFilePath, content + '\n', 'utf-8');
    } catch (error: any) {
      console.error(`[LLMLogger] âŒ Failed to append to log: ${error.message}`);
    }
  }

  /**
   * Log session start
   */
  async logSessionStart(sessionId: string, chatSessionId?: string, userId?: string): Promise<void> {
    const entry = `
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                            NEW SESSION STARTED                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“… Timestamp: ${new Date().toISOString()}
ğŸ†” Session ID: ${sessionId}
ğŸ’¬ Chat Session ID: ${chatSessionId || 'N/A'}
ğŸ‘¤ User ID: ${userId || 'N/A'}

`;
    await this.appendToLog(entry);
  }

  /**
   * Log iteration start
   */
  async logIterationStart(
    iteration: number,
    sessionId: string,
    currentNode: string,
    userMessage?: string
  ): Promise<void> {
    const entry = `
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”„ ITERATION ${iteration}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â° Timestamp: ${new Date().toISOString()}
ğŸ†” Session: ${sessionId.substring(0, 8)}...
ğŸ¯ Current Node: ${currentNode}
${userMessage ? `ğŸ‘¤ User Message: ${userMessage}\n` : ''}`;
    await this.appendToLog(entry);
  }

  /**
   * Log agent context state (before execution)
   */
  async logContextState(state: AgentContextState, label: string = 'CONTEXT STATE'): Promise<void> {
    const entry = `
ğŸ“Š [${label}]
   Current Node: ${state.currentNode}
   Previous Node: ${state.previousNode || '(none)'}

   ğŸ Flags:
${JSON.stringify(state.context.flags || {}, null, 6)}

   ğŸ“ Mandatory Fields:
      - customers_main_ask: ${state.context.customers_main_ask || '(not set)'}
      - customer_phone_number: ${state.context.customer_phone_number || '(not set)'}

   ğŸ“‹ Other Context Fields:
      - customer_name: ${state.context.customer_name || '(not set)'}
      - service_catalog: ${state.context.matching_service_catalog_to_solve_customers_issue || '(not set)'}
      - task_id: ${state.context.task_id || '(not set)'}
      - next_node_to_go_to: ${state.context.next_node_to_go_to || '(not set)'}
      - next_course_of_action: ${state.context.next_course_of_action || '(not set)'}

   ğŸ›¤ï¸  Node Traversal Path: ${JSON.stringify(state.context.node_traversal_path || [])}

   ğŸ’¬ Conversation History (${(state.context.summary_of_conversation_on_each_step_until_now || []).length} exchanges):
${(state.context.summary_of_conversation_on_each_step_until_now || []).slice(-3).map((ex: any, idx: number) => `      ${ex.index || idx}. [CUSTOMER] ${ex.customer.substring(0, 80)}${ex.customer.length > 80 ? '...' : ''}\n         [AGENT] ${ex.agent.substring(0, 80)}${ex.agent.length > 80 ? '...' : ''}`).join('\n')}
`;
    await this.appendToLog(entry);
  }

  /**
   * Log LLM call (before making the call)
   */
  async logLLMCall(args: {
    agentType: string;
    model: string;
    messages: ChatCompletionMessageParam[];
    temperature: number;
    maxTokens: number;
    jsonMode: boolean;
    tools?: any[];
    sessionId?: string;
  }): Promise<void> {
    const systemMsg = args.messages.find(m => m.role === 'system');
    const userMsg = args.messages.find(m => m.role === 'user');
    const systemPrompt = systemMsg && typeof systemMsg.content === 'string' ? systemMsg.content : '';
    const userPrompt = userMsg && typeof userMsg.content === 'string' ? userMsg.content : '';

    const entry = `
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¤– [LLM CALL] Agent: ${args.agentType}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â° Timestamp: ${new Date().toISOString()}
${args.sessionId ? `ğŸ†” Session: ${args.sessionId.substring(0, 8)}...\n` : ''}ğŸ”§ Model: ${args.model}
ğŸŒ¡ï¸  Temperature: ${args.temperature}
ğŸ“Š Max Tokens: ${args.maxTokens}
ğŸ“ JSON Mode: ${args.jsonMode ? 'YES' : 'NO'}
ğŸ’¬ Message Count: ${args.messages.length}
${args.tools ? `ğŸ› ï¸  Tools: ${args.tools.length} available\n` : ''}
â”Œâ”€â”€â”€ SYSTEM PROMPT (FULL) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
${systemPrompt}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€ USER PROMPT (FULL) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
${userPrompt}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

${args.messages.length > 2 ? `ğŸ“œ Full Message History (${args.messages.length} messages):\n${args.messages.map((msg, idx) => `   ${idx + 1}. [${msg.role.toUpperCase()}] ${typeof msg.content === 'string' ? msg.content.substring(0, 150) : '(complex)'}...`).join('\n')}\n` : ''}`;
    await this.appendToLog(entry);
  }

  /**
   * Log LLM response (after receiving the response)
   */
  async logLLMResponse(args: {
    agentType: string;
    content: string;
    tokensUsed: number;
    promptTokens: number;
    completionTokens: number;
    costCents: number;
    latencyMs: number;
    toolCalls?: any[];
    sessionId?: string;
  }): Promise<void> {
    const entry = `
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… [LLM RESPONSE] Agent: ${args.agentType}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â° Timestamp: ${new Date().toISOString()}
${args.sessionId ? `ğŸ†” Session: ${args.sessionId.substring(0, 8)}...\n` : ''}ğŸ“Š Tokens: ${args.tokensUsed} (prompt: ${args.promptTokens}, completion: ${args.completionTokens})
ğŸ’° Cost: $${(args.costCents / 100).toFixed(4)}
âš¡ Latency: ${args.latencyMs}ms
${args.toolCalls ? `ğŸ› ï¸  Tool Calls: ${args.toolCalls.length}\n${JSON.stringify(args.toolCalls, null, 2)}\n` : ''}
â”Œâ”€â”€â”€ RESPONSE (FULL) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
${args.content}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

`;
    await this.appendToLog(entry);
  }

  /**
   * Log agent execution (worker, navigator, etc.)
   */
  async logAgentExecution(args: {
    agentType: 'worker_reply' | 'worker_mcp' | 'navigator';
    nodeName: string;
    result: any;
    sessionId?: string;
  }): Promise<void> {
    const entry = `
ğŸ­ [AGENT EXECUTION] ${args.agentType.toUpperCase()}
   Node: ${args.nodeName}
   ${args.sessionId ? `Session: ${args.sessionId.substring(0, 8)}...\n   ` : ''}Timestamp: ${new Date().toISOString()}

   Result:
${JSON.stringify(args.result, null, 6)}

`;
    await this.appendToLog(entry);
  }

  /**
   * Log navigator decision
   */
  async logNavigatorDecision(args: {
    currentNode: string;
    decision: string;
    nextNode: string;
    reason: string;
    contextUpdates?: any;
    sessionId?: string;
  }): Promise<void> {
    const entry = `
ğŸ§­ [NAVIGATOR DECISION]
   From Node: ${args.currentNode}
   Decision: ${args.decision}
   Next Node: ${args.nextNode}
   Reason: ${args.reason}
   ${args.sessionId ? `Session: ${args.sessionId.substring(0, 8)}...\n   ` : ''}Timestamp: ${new Date().toISOString()}
   ${args.contextUpdates ? `\n   Context Updates:\n${JSON.stringify(args.contextUpdates, null, 6)}` : ''}

`;
    await this.appendToLog(entry);
  }

  /**
   * Log conversation turn (user message + AI response)
   */
  async logConversationTurn(args: {
    userMessage: string;
    aiResponse: string;
    sessionId?: string;
  }): Promise<void> {
    const entry = `
ğŸ’¬ [CONVERSATION TURN]
   ${args.sessionId ? `Session: ${args.sessionId.substring(0, 8)}...\n   ` : ''}Timestamp: ${new Date().toISOString()}

   ğŸ‘¤ USER: ${args.userMessage}

   ğŸ¤– AI: ${args.aiResponse}

`;
    await this.appendToLog(entry);
  }

  /**
   * Log iteration end
   */
  async logIterationEnd(args: {
    iteration: number;
    nextNode: string;
    conversationEnded: boolean;
    endReason?: string;
    sessionId?: string;
  }): Promise<void> {
    const entry = `
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ”ï¸  ITERATION ${args.iteration} COMPLETE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Next Node: ${args.nextNode}
   Conversation Ended: ${args.conversationEnded ? 'YES' : 'NO'}
   ${args.endReason ? `End Reason: ${args.endReason}\n   ` : ''}${args.sessionId ? `Session: ${args.sessionId.substring(0, 8)}...\n   ` : ''}Timestamp: ${new Date().toISOString()}

`;
    await this.appendToLog(entry);
  }

  /**
   * Log session end
   */
  async logSessionEnd(args: {
    sessionId: string;
    endReason: string;
    totalIterations: number;
    totalMessages: number;
  }): Promise<void> {
    const entry = `
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              SESSION ENDED                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ†” Session ID: ${args.sessionId}
ğŸ“… Timestamp: ${new Date().toISOString()}
ğŸ End Reason: ${args.endReason}
ğŸ”„ Total Iterations: ${args.totalIterations}
ğŸ’¬ Total Messages: ${args.totalMessages}

`;
    await this.appendToLog(entry);
  }

  /**
   * Log error
   */
  async logError(args: {
    component: string;
    error: Error;
    context?: any;
    sessionId?: string;
  }): Promise<void> {
    const entry = `
âŒ [ERROR] ${args.component}
   ${args.sessionId ? `Session: ${args.sessionId.substring(0, 8)}...\n   ` : ''}Timestamp: ${new Date().toISOString()}
   Error: ${args.error.message}
   Stack: ${args.error.stack}
   ${args.context ? `\n   Context:\n${JSON.stringify(args.context, null, 6)}` : ''}

`;
    await this.appendToLog(entry);
  }

  /**
   * Log arbitrary message
   */
  async log(message: string): Promise<void> {
    const entry = `[${new Date().toISOString()}] ${message}`;
    await this.appendToLog(entry);
  }
}

/**
 * Singleton instance
 */
let instance: LLMLoggerService | null = null;

export function getLLMLogger(): LLMLoggerService {
  if (!instance) {
    instance = new LLMLoggerService();
  }
  return instance;
}
